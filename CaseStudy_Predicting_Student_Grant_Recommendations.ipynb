{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "CaseStudy_Predicting Student Grant Recommendations.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv4HUZTjLzoq"
      },
      "source": [
        "# Objective : Student Grant Recommendation\n",
        "\n",
        "We have historical student performance data and their grant recommendation outcomes in the form of a comma separated value file named student_records.csv. Each data sample consists of the following attributes.\n",
        "\n",
        "• Name (the student name)\n",
        "• OverallGrade (overall grade obtained)\n",
        "• Obedient (whether they were diligent during their course of stay)\n",
        "• ResearchScore (marks obtained in their research work)\n",
        "• ProjectScore (marks obtained in the project)\n",
        "• Recommend (whether they got the grant recommendation)\n",
        "\n",
        "The main objective is to build a predictive model based on this data such that we can predict for any future student whether they will be recommended for the grant based on their performance attributes."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "kTqNyFOLLzos"
      },
      "source": [
        "Step 1: Data Retrieval\n",
        "----------------------\n",
        "Here, we will leverage the pandas framework to retrieve the data from the CSV file. The following snippet shows us how to retrieve the data and view it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQdhW7GzLzot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "49805afa-b7e3-4b95-f69a-ea412ed18047"
      },
      "source": [
        "import pandas as pd\n",
        "#--turn of warning messages\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "#--get data\n",
        "df = pd.read_csv('student_records.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>OverallGrade</th>\n",
              "      <th>Obedient</th>\n",
              "      <th>ResearchScore</th>\n",
              "      <th>ProjectScore</th>\n",
              "      <th>Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Henry</td>\n",
              "      <td>A</td>\n",
              "      <td>Y</td>\n",
              "      <td>90</td>\n",
              "      <td>85</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>C</td>\n",
              "      <td>N</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Holmes</td>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "      <td>75</td>\n",
              "      <td>71</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marvin</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Simon</td>\n",
              "      <td>A</td>\n",
              "      <td>Y</td>\n",
              "      <td>92</td>\n",
              "      <td>79</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Robert</td>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Trent</td>\n",
              "      <td>C</td>\n",
              "      <td>Y</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
              "0   Henry            A        Y             90            85       Yes\n",
              "1    John            C        N             85            51       Yes\n",
              "2   David            F        N             10            17        No\n",
              "3  Holmes            B        Y             75            71        No\n",
              "4  Marvin            E        N             20            30        No\n",
              "5   Simon            A        Y             92            79       Yes\n",
              "6  Robert            B        Y             60            59        No\n",
              "7   Trent            C        Y             75            33        No"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "N4LEvUMPLzo0"
      },
      "source": [
        "Step 2: Data Preparation\n",
        "------------------------\n",
        "Based on the dataset (above), we do not have any data errors or missing values, hence we will mainly focus on feature engineering and scaling in this section."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "hPZLvcGJLzo1"
      },
      "source": [
        "Step 3 : Feature Extraction and Engineering\n",
        "-------------------------------------------\n",
        "Let’s start by extracting the existing features from the dataset and the outcomes; in separate variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjwYsgZ7Lzo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1faf7277-fb96-4f77-fa7d-9664a6c5878f"
      },
      "source": [
        "#--get features and corresponding outcomes\n",
        "feature_names = ['OverallGrade', 'Obedient', 'ResearchScore', 'ProjectScore']\n",
        "training_features = df[feature_names]\n",
        "\n",
        "outcome_name = ['Recommend']\n",
        "outcome_labels = df[outcome_name]\n",
        "\n",
        "print(training_features)\n",
        "print(\"----------------\")\n",
        "print(outcome_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0            A        Y             90            85\n",
            "1            C        N             85            51\n",
            "2            F        N             10            17\n",
            "3            B        Y             75            71\n",
            "4            E        N             20            30\n",
            "5            A        Y             92            79\n",
            "6            B        Y             60            59\n",
            "7            C        Y             75            33\n",
            "----------------\n",
            "  Recommend\n",
            "0       Yes\n",
            "1       Yes\n",
            "2        No\n",
            "3        No\n",
            "4        No\n",
            "5       Yes\n",
            "6        No\n",
            "7        No\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "2Q2-YKF7Lzo9"
      },
      "source": [
        "Now that we have extracted our initial available features from the data and their corresponding outcome labels, let’s separate out our available features based on their type (numerical and categorical)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wte0jbRpLzo-"
      },
      "source": [
        "#--list down features based on type\n",
        "numeric_feature_names = ['ResearchScore', 'ProjectScore']\n",
        "categoricial_feature_names = ['OverallGrade', 'Obedient']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Gz1fNocxLzpC"
      },
      "source": [
        "We will now use a standard scalar from scikit-learn to scale or normalize our two numeric scorebased attributes using the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMrtdeoLzpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "709e15ed-eeea-476e-dee6-982cd330cde2"
      },
      "source": [
        "#--scale or normalize our two numeric score-based attributes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "\n",
        "# fit scaler on numeric features\n",
        "ss.fit(training_features[numeric_feature_names])\n",
        "\n",
        "# scale numeric features now\n",
        "training_features[numeric_feature_names] = ss.transform(training_features[numeric_feature_names])\n",
        "\n",
        "# view updated feature-set\n",
        "print(training_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0            A        Y       0.899583      1.376650\n",
            "1            C        N       0.730648     -0.091777\n",
            "2            F        N      -1.803390     -1.560203\n",
            "3            B        Y       0.392776      0.772004\n",
            "4            E        N      -1.465519     -0.998746\n",
            "5            A        Y       0.967158      1.117516\n",
            "6            B        Y      -0.114032      0.253735\n",
            "7            C        Y       0.392776     -0.869179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "HKTKsZzlLzpL"
      },
      "source": [
        "Now that we have successfully scaled our numeric features, let’s handle our categorical features and carry out the necessary feature engineering needed based on the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PthM3JoFLzpM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b0da1891-d3ed-4261-a163-eae147f3e774"
      },
      "source": [
        "#--Engineering Categorical Features\n",
        "training_features = pd.get_dummies(training_features, columns=categoricial_feature_names)\n",
        "\n",
        "# view newly engineering features\n",
        "print(training_features)\n",
        "\n",
        "# We have converted our categoricial data into numeric. \n",
        "# or we can say we have done feature engineering over categorical data."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ResearchScore  ProjectScore  ...  Obedient_N  Obedient_Y\n",
            "0       0.899583      1.376650  ...           0           1\n",
            "1       0.730648     -0.091777  ...           1           0\n",
            "2      -1.803390     -1.560203  ...           1           0\n",
            "3       0.392776      0.772004  ...           0           1\n",
            "4      -1.465519     -0.998746  ...           1           0\n",
            "5       0.967158      1.117516  ...           0           1\n",
            "6      -0.114032      0.253735  ...           0           1\n",
            "7       0.392776     -0.869179  ...           0           1\n",
            "\n",
            "[8 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gWBekh8LzpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82b6199f-a039-4f7d-e976-0192a1036c1e"
      },
      "source": [
        "#--get list of new categorical features\n",
        "categorical_engineered_features = list(set(training_features.columns) - set(numeric_feature_names))\n",
        "\n",
        "print(categorical_engineered_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['OverallGrade_A', 'OverallGrade_B', 'Obedient_N', 'OverallGrade_F', 'OverallGrade_E', 'OverallGrade_C', 'Obedient_Y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "xu3b6zaoLzpV"
      },
      "source": [
        "Step 4 : Modeling\n",
        "-----------------\n",
        "We will now build a simple classification (supervised) model based on our feature set by using the logistic regression algorithm. The following code depicts how to build the supervised model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZUJ7hjhLzpW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3bddc8da-a14e-4f7e-de15-0bc18fbaa1b3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import warnings; warnings.simplefilter('ignore')  \n",
        "\n",
        "#--fit the model  \n",
        "lrg = LogisticRegression()\n",
        "model = lrg.fit(training_features, outcome_labels)\n",
        "#--view model parameters \n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "gEWThXNyLzpd"
      },
      "source": [
        "Thus, we now have our supervised learning model based on the logistic regression model with L2 regularization, as we can see from the parameters in the above output."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "RHU28KsBLzpe"
      },
      "source": [
        "Step 5 : Model Evaluation\n",
        "-------------------------\n",
        "Typically model evaluation is done based on some validation dataset that is different from the training dataset to prevent overfitting or biasing the model. Since this is an example on a toy dataset, let’s evaluate the performance of our model on the training data using the following snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpcpmZpwLzpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c9a5afae-ed76-4d68-c06b-b7a84fe08cf9"
      },
      "source": [
        "#--simple evaluation on training data\n",
        "pred_labels = model.predict(training_features)\n",
        "actual_labels = np.array(outcome_labels['Recommend'])\n",
        "\n",
        "#--evaluate model performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print('Accuracy:', float(accuracy_score(actual_labels, pred_labels))*100, '%')\n",
        "\n",
        "print('Classification Stats:')\n",
        "print(classification_report(actual_labels, pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100.0 %\n",
            "Classification Stats:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          No       1.00      1.00      1.00         5\n",
            "         Yes       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "fc2RR34FLzpi"
      },
      "source": [
        "Step 6 : Model Deployment  -- optional in our case\n",
        "-------------------------\n",
        "We built our first supervised learning model, and to deploy this model typically in a system or server, we need to persist the model. We also need to save the scalar object we used to scale the numerical features since we use it to transform the numeric features of new data samples. The following snippet depicts a way to store the model and scalar objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jz58kmLzpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d9ab0df-f1f6-4056-ddda-e43e3d44b025"
      },
      "source": [
        "#--Model Deployment  -- optional in our case\n",
        "from sklearn.externals import joblib\n",
        "import os\n",
        "#--save models to be deployed on server\n",
        "if not os.path.exists('Model'):\n",
        "    os.mkdir('Model')\n",
        "if not os.path.exists('Scaler'):\n",
        "    os.mkdir('Scaler') \n",
        "    \n",
        "joblib.dump(model, r'Model/model.pickle') \n",
        "joblib.dump(ss, r'Scaler/scaler.pickle')\n",
        "\n",
        "# Check both the folders under  C:\\Program Files\\Python36"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scaler/scaler.pickle']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "P68MoNGwLzpo"
      },
      "source": [
        "Step 7 : Prediction in Action\n",
        "-----------------------------\n",
        "We are now ready to start predicting with our newly built and deployed model! To start predictions, we need to load our model and scalar objects into memory. The following code helps us do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RzwFsX_Lzps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3ff2cf7b-0c9d-4882-b207-d1cb78f2477f"
      },
      "source": [
        "#--Prediction in Action\n",
        "#--load model and scaler objects\n",
        "model = joblib.load(r'Model/model.pickle')\n",
        "scaler = joblib.load(r'Scaler/scaler.pickle')\n",
        "\n",
        "# We have some sample new student records (for two students) \n",
        "# for which we want our model to predict if they will get the \n",
        "# grant recommendation. \n",
        "# Let’s retrieve and view this data using the following code.\n",
        "\n",
        "#--data retrieval\n",
        "new_data = pd.DataFrame([{'Name': 'Ninad', 'OverallGrade': 'F', 'Obedient': 'N', 'ResearchScore': 30, 'ProjectScore': 20},\n",
        "                  {'Name': 'Thomas', 'OverallGrade': 'A', 'Obedient': 'Y', 'ResearchScore': 78, 'ProjectScore': 80}])\n",
        "\n",
        "print(new_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Name OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0   Ninad            F        N             30            20\n",
            "1  Thomas            A        Y             78            80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKGOcBiLzpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "9b01a15c-e98b-458b-9c1d-29fcd01811dc"
      },
      "source": [
        "# w.r.t new data\n",
        "# We will now carry out the tasks relevant to \n",
        "# data preparation—feature extraction, engineering, and scaling \n",
        "# in the following code snippet.\n",
        "\n",
        "#--data preparation   \n",
        "new_training_features = new_data[feature_names]\n",
        "\n",
        "#--scaling ..\n",
        "scaler.fit(new_training_features[numeric_feature_names])\n",
        "new_training_features[numeric_feature_names] = scaler.transform(new_training_features[numeric_feature_names])\n",
        "\n",
        "#--engineering categorical variables .. \n",
        "new_training_features = pd.get_dummies(new_training_features, columns=categoricial_feature_names)\n",
        "\n",
        "\n",
        "new_training_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ResearchScore</th>\n",
              "      <th>ProjectScore</th>\n",
              "      <th>OverallGrade_A</th>\n",
              "      <th>OverallGrade_F</th>\n",
              "      <th>Obedient_N</th>\n",
              "      <th>Obedient_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ResearchScore  ProjectScore  ...  Obedient_N  Obedient_Y\n",
              "0           -1.0          -1.0  ...           1           0\n",
              "1            1.0           1.0  ...           0           1\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "OK_OiounLzpz"
      },
      "source": [
        "We now have the relevant features for the new students! However we can see that some of the categorical features are missing based on some grades like B, C, and E. This is because none of these students obtained those grades but we still need those attributes because the model was trained on all attributes including these. The following snippet helps us identify and add the missing categorical features.\n",
        "\n",
        "We add the value for each of those features as 0 for each student since they did not obtain those grades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaTeIaDMLzp0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f7ef2ca6-35b5-4c8e-e44f-75e8e9f6b263"
      },
      "source": [
        "# add missing categorical feature columns\n",
        "current_categorical_engineered_features = set(new_training_features.columns) - set(numeric_feature_names)\n",
        "\n",
        "missing_features = set(categorical_engineered_features) - current_categorical_engineered_features\n",
        "\n",
        "for feature in missing_features:\n",
        "    # add zeros since feature is absent in these data samples\n",
        "    new_training_features[feature] = [0] * len(new_training_features)\n",
        "    \n",
        "\n",
        "# view final feature set\n",
        "print(new_training_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ResearchScore  ProjectScore  ...  OverallGrade_E  OverallGrade_B\n",
            "0           -1.0          -1.0  ...               0               0\n",
            "1            1.0           1.0  ...               0               0\n",
            "\n",
            "[2 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OETcG7GLzp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "133d2428-b0bb-4bea-9bf9-61e9c825b974"
      },
      "source": [
        "# We have our complete feature set ready for both the new students. \n",
        "# Let’s put our model to the test and get the predictions \n",
        "# with regard to grant recommendations!\n",
        "\n",
        "pred_labels1 = model.predict(new_training_features)\n",
        "new_data['Recommend'] = pred_labels1\n",
        "new_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>OverallGrade</th>\n",
              "      <th>Obedient</th>\n",
              "      <th>ResearchScore</th>\n",
              "      <th>ProjectScore</th>\n",
              "      <th>Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ninad</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thomas</td>\n",
              "      <td>A</td>\n",
              "      <td>Y</td>\n",
              "      <td>78</td>\n",
              "      <td>80</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
              "0   Ninad            F        N             30            20        No\n",
              "1  Thomas            A        Y             78            80       Yes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "qSlTU10yLzqA"
      },
      "source": [
        "We can clearly see from above steps that our model has predicted grant recommendation labels for both the new students. \n",
        "\n",
        "Thomas clearly being diligent, having a straight A average and decent scores, is most likely to get the grant recommendation as compared to Ninad. Thus we can see that our model has learned how to predict grant recommendation outcomes based on past historical student data."
      ]
    }
  ]
}